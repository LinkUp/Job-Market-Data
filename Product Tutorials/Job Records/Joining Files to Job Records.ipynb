{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining files together\n",
    "\n",
    "The purpose of this file is to convey methodology and logic that can be used to join our files together.  To this end, we will cover each our of Raw 2.0 files using a slice of the full job records.  These methodologies can be scaled up in a SQL data warehouse or by chunking the files depending on the subset you are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "import sqlite3\n",
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Job Records\n",
    "\n",
    "### Job records is the core table.  Everything will be joined into Job Records.\n",
    "\n",
    "##### I will only be using a small subset of the columns for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading raw sample slice\n",
    "with tarfile.open('raw-sample.tar.gz', \"r:*\") as tar:\n",
    "    # Get path to the job_records file within the tarfile\n",
    "    csv_path = tar.getnames()[1]\n",
    "    # Load job records file into pandas dataframe\n",
    "    job_records = pd.read_csv(tar.extractfile(csv_path),\n",
    "                    parse_dates = ['created','delete_date'],\n",
    "                    low_memory = False,\n",
    "                    usecols = ['hash','title','company_id','created','delete_date','company_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Company_ticker File\n",
    "\n",
    "##### I am only joining the Company Ticker file for this demo. The Company Sedol, Company ISIN, Company CUSIP files would all be join using the same method.\n",
    "\n",
    "##### I am only joining primary information, and only based on created date as that is a good starting point.  Please reach out to Linkup if you would like to discuss options for joining to use information on multiple dates to account for jobs that span changes/M&A activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read PIT Ticker File\n",
    "company_ticker = pd.read_csv('company_ticker_2021-01-31.csv.gz',\n",
    "                        parse_dates = ['start_date','end_date'])\n",
    "                      \n",
    "# Filter for only primary exchange and columns needed for join\n",
    "company_ticker = company_ticker[company_ticker.primary_flag == True]\n",
    "\n",
    "# Formatting Timestamps for Merge and dealing with missing values\n",
    "company_ticker['start_date'] = company_ticker['start_date'].fillna(str(job_records.created.min().date()))\n",
    "company_ticker['start_date'] = pd.to_datetime(company_ticker['start_date'])\n",
    "company_ticker['end_date'] = company_ticker['end_date'].fillna(str(job_records.created.max().date()))\n",
    "company_ticker['end_date'] = pd.to_datetime(company_ticker['end_date'])\n",
    "\n",
    "# Make the db in memory\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Write the tables\n",
    "job_records.to_sql('Job_Records', conn, index=False)\n",
    "company_ticker.to_sql('company_ticker', conn, index=False)\n",
    "\n",
    "# Query and create new joined table\n",
    "qry = '''\n",
    "    SELECT Job_Records.*,\n",
    "    company_ticker.ticker_symbol,\n",
    "    company_ticker.stock_exchange_country,\n",
    "    company_ticker.stock_exchange_name,\n",
    "    company_ticker.primary_flag\n",
    "    \n",
    "    FROM Job_Records\n",
    "    \n",
    "    LEFT JOIN company_ticker\n",
    "    ON (Job_Records.created between company_ticker.start_date and company_ticker.end_date and\n",
    "       Job_Records.company_id = company_ticker.company_id);\n",
    "    '''\n",
    "job_records_joined = pd.read_sql_query(qry, conn)\n",
    "\n",
    "FS_reference = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join PIT Company Reference\n",
    "\n",
    "##### For the PIT Company Reference File, most use-cases only require joining the most current company information to all records historically. This can be done by taking the records whose end date is null and joining on company_id.  Below we have joined using point in time infomration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIT_Company_Reference = pd.read_csv('raw_pit_company_reference_full_2020-12-31.csv.gz')\n",
    "\n",
    "# Filter Company Reference file to include only the companies that we pulled\n",
    "#PIT_Company_Reference = PIT_Company_Reference[PIT_Company_Reference.company_id.isin(job_records.company_id.unique())]\n",
    "\n",
    "# Filter Company Reference for the latest Information\n",
    "#PIT_Company_Reference = PIT_Company_Reference[PIT_Company_Reference.end_date.isnull()]\n",
    "\n",
    "#Set null records to todays date\n",
    "PIT_Company_Reference['end_date'] = PIT_Company_Reference['end_date'].fillna(str(job_records.created.max().date()))\n",
    "PIT_Company_Reference['end_date'] = pd.to_datetime(PIT_Company_Reference['end_date'])\n",
    "\n",
    "# Make the db in memory\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Write the tables\n",
    "job_records_joined.to_sql('Job_Records', conn, index=False)\n",
    "PIT_Company_Reference.to_sql('PIT_Company_Reference', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    SELECT \n",
    "        Job_Records.*, \n",
    "        PIT_Company_Reference.company_url,\n",
    "        PIT_Company_Reference.lei,\n",
    "        PIT_Company_Reference.open_perm_id\n",
    "        \n",
    "    FROM Job_Records\n",
    "    LEFT JOIN PIT_Company_Reference\n",
    "    ON Job_Records.company_id = PIT_Company_Reference.company_id and\n",
    "        Job_Records.created BETWEEN \n",
    "            PIT_Company_Reference.start_date and \n",
    "            PIT_Company_Reference.end_date\n",
    "        ;\n",
    "'''\n",
    "\n",
    "job_records_joined = pd.read_sql_query(qry, conn)\n",
    "\n",
    "PIT_Company_Reference = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Scrape Log\n",
    "\n",
    "##### Here I will do a basic join to show the date of the next scrape change.  The primary purpose of this is so that if you see outliers, you can see when the next code change was.  If it was shortly after the outlier, the outlier is likely a scrape break vs a true signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Scrape Log\n",
    "Scrape_Log = pd.read_csv('raw_company_scrape_log_full_2020-12-31.csv.gz')\n",
    "\n",
    "# Filter Scrape Log to only include code changes for the companies that we pulled\n",
    "Scrape_Log = Scrape_Log[Scrape_Log.scrape_changed == True]\n",
    "Scrape_Log = Scrape_Log[Scrape_Log.company_id.isin(job_records.company_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift Date for SQL query convenience\n",
    "Scrape_Log['date_shifted'] = Scrape_Log.groupby(['company_id'])['date'].shift(1)\n",
    "Scrape_Log['date_shifted'] = Scrape_Log['date_shifted'].fillna('2007-01-01')\n",
    "\n",
    "Scrape_Log['date_shifted'] = pd.to_datetime(Scrape_Log['date_shifted'])\n",
    "Scrape_Log['date'] = pd.to_datetime(Scrape_Log['date'])\n",
    "# Make the db in memory\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Write the tables\n",
    "job_records_joined.to_sql('Job_Records', conn, index=False)\n",
    "Scrape_Log.to_sql('Scrape_Log', conn, index=False)\n",
    "\n",
    "# Query and create new joined table\n",
    "qry = '''\n",
    "    SELECT Job_Records.*,\n",
    "    Scrape_Log.date as Next_Scrape_Change\n",
    "    \n",
    "    FROM Job_Records\n",
    "    \n",
    "    LEFT JOIN Scrape_Log\n",
    "    ON (Job_Records.created between Scrape_Log.date_shifted and Scrape_Log.date and\n",
    "       Job_Records.company_id = Scrape_Log.company_id);\n",
    "    '''\n",
    "job_records_joined = pd.read_sql_query(qry, conn)\n",
    "\n",
    "Scrape_Log = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load Descriptions file\n",
    "Job_Descriptions = pd.DataFrame(\n",
    "        list(map(lambda x: (x[0].text,x[1].text),\n",
    "                 ET.parse('../raw-sample/raw-sample-descriptions.xml').getroot())), \n",
    "'''    \n",
    "with tarfile.open('raw-sample.tar.gz', \"r:*\") as tar:\n",
    "    # Get path to the job_records file within the tarfile\n",
    "    csv_path = tar.getnames()[0]\n",
    "    # Load job records file into pandas dataframe\n",
    "    #job_records = pd.read_csv(tar.extractfile(csv_path),\n",
    "    #    columns = ['job_hash','description'])\n",
    "\n",
    "    Job_Descriptions = pd.DataFrame(\n",
    "        list(map(lambda x: (x[0].text,x[1].text),\n",
    "                 ET.parse(tar.extractfile(csv_path)).getroot())),\n",
    "        columns = ['job_hash','description'])\n",
    "# Make the db in memory\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Write the tables\n",
    "job_records_joined.to_sql('Job_Records', conn, index=False)\n",
    "Job_Descriptions.to_sql('Job_Descriptions', conn, index=False)\n",
    "\n",
    "qry = '''\n",
    "    SELECT \n",
    "        Job_Records.*, \n",
    "        Job_Descriptions.description\n",
    "    \n",
    "    \n",
    "    FROM Job_Records\n",
    "    LEFT JOIN Job_Descriptions\n",
    "    ON (Job_Records.hash = Job_Descriptions.job_hash);\n",
    "'''\n",
    "job_records_joined = pd.read_sql_query(qry, conn)\n",
    "\n",
    "Job_Descriptions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Results of Big Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>title</th>\n",
       "      <th>company_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>created</th>\n",
       "      <th>delete_date</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>stock_exchange_country</th>\n",
       "      <th>stock_exchange_name</th>\n",
       "      <th>primary_flag</th>\n",
       "      <th>company_url</th>\n",
       "      <th>lei</th>\n",
       "      <th>open_perm_id</th>\n",
       "      <th>Next_Scrape_Change</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0234422f9c5eff7f6d1d008c3c31dae6</td>\n",
       "      <td>UI Artist, Double Helix Games, Amazon Game Stu...</td>\n",
       "      <td>469</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>2015-06-20 02:39:07+00:00</td>\n",
       "      <td>2015-09-18 07:51:10+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>US</td>\n",
       "      <td>NAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.amazon.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-01-30 00:00:00</td>\n",
       "      <td>Amazon is all in on games.\\n\\nWe believe the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0c392d37eb6dfb15b1ffc2a48b8d95e7</td>\n",
       "      <td>Warehouse Team Member (Seasonal, Part Time, Fl...</td>\n",
       "      <td>469</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>2019-01-15 16:06:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>US</td>\n",
       "      <td>NAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.amazon.com</td>\n",
       "      <td>ZXTILKJKG63JELOEG630</td>\n",
       "      <td>4295905494</td>\n",
       "      <td>2019-07-26 00:00:00</td>\n",
       "      <td>Shifts:\\n\\nOver-night, Early Morning, Day, Eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0ee6d7263a67121e8405af8ad8fdef2a</td>\n",
       "      <td>Responsable des opérations de contrôle d'inven...</td>\n",
       "      <td>469</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>2018-04-17 15:04:00+00:00</td>\n",
       "      <td>2018-04-18 15:05:00+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>US</td>\n",
       "      <td>NAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.amazon.com</td>\n",
       "      <td>ZXTILKJKG63JELOEG630</td>\n",
       "      <td>4295905494</td>\n",
       "      <td>2019-07-26 00:00:00</td>\n",
       "      <td>ous aimez l'action ?\\n\\nVous aimeriez travaill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0aaf97d36a5279ac18a43d1e34344232</td>\n",
       "      <td>Relationship Manager-Newton/Waltham, MA Area</td>\n",
       "      <td>381</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>2015-10-15 20:58:31+00:00</td>\n",
       "      <td>2015-10-23 06:54:04+00:00</td>\n",
       "      <td>BAC</td>\n",
       "      <td>US</td>\n",
       "      <td>NYS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.bankofamerica.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-10-23 00:00:00</td>\n",
       "      <td>Located in a banking center, Relationship Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>05e060a4db459d502ed71fc78ea75f62</td>\n",
       "      <td>Database Administrator II - AMZ1781</td>\n",
       "      <td>469</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>2017-07-02 09:46:00+00:00</td>\n",
       "      <td>2017-07-22 19:00:00+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>US</td>\n",
       "      <td>NAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.amazon.com</td>\n",
       "      <td>ZXTILKJKG63JELOEG630</td>\n",
       "      <td>4295905494</td>\n",
       "      <td>2017-07-14 00:00:00</td>\n",
       "      <td>MULTIPLE POSITIONS AVAILABLE Company: Amazon C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015682</th>\n",
       "      <td>fce9446a1c82c043b885ec53bd7c79e9</td>\n",
       "      <td>Client Service Representative</td>\n",
       "      <td>381</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>2017-10-10 00:03:00+00:00</td>\n",
       "      <td>2017-10-17 04:16:56+00:00</td>\n",
       "      <td>BAC</td>\n",
       "      <td>US</td>\n",
       "      <td>NYS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.bankofamerica.com</td>\n",
       "      <td>9DJT3UXIJIZJI4WXO774</td>\n",
       "      <td>8589934339</td>\n",
       "      <td>2019-11-22 00:00:00</td>\n",
       "      <td>Job Description:\\n\\nFinancial Center Client Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015683</th>\n",
       "      <td>f69454c25df4c853541eecdfc4a3d0ef</td>\n",
       "      <td>DCO Lead(Away)</td>\n",
       "      <td>469</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>2017-11-08 16:05:00+00:00</td>\n",
       "      <td>2017-11-15 16:18:17+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>US</td>\n",
       "      <td>NAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.amazon.com</td>\n",
       "      <td>ZXTILKJKG63JELOEG630</td>\n",
       "      <td>4295905494</td>\n",
       "      <td>2019-07-26 00:00:00</td>\n",
       "      <td>Are you passionate about finding process impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015684</th>\n",
       "      <td>f1399ba8d1ae6adddad701beb823a8f8</td>\n",
       "      <td>Director of Inclusion and Diversity - Minneton...</td>\n",
       "      <td>383</td>\n",
       "      <td>UnitedHealth Group Inc.</td>\n",
       "      <td>2017-07-25 22:08:00+00:00</td>\n",
       "      <td>2017-08-29 15:50:44+00:00</td>\n",
       "      <td>UNH</td>\n",
       "      <td>US</td>\n",
       "      <td>NYS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.unitedhealthgroup.com</td>\n",
       "      <td>549300GHBMY8T5GXDE41</td>\n",
       "      <td>5046300101</td>\n",
       "      <td>2017-09-06 00:00:00</td>\n",
       "      <td>Here, you'll help attract, lead, support and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015685</th>\n",
       "      <td>f6a9ba8e6c257788e5599388f770dfd0</td>\n",
       "      <td>Registered Client Associate</td>\n",
       "      <td>381</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>2016-08-26 16:26:37+00:00</td>\n",
       "      <td>2016-08-30 17:50:11+00:00</td>\n",
       "      <td>BAC</td>\n",
       "      <td>US</td>\n",
       "      <td>NYS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.bankofamerica.com</td>\n",
       "      <td>9DJT3UXIJIZJI4WXO774</td>\n",
       "      <td>8589934339</td>\n",
       "      <td>2017-01-30 00:00:00</td>\n",
       "      <td>Business Overview\\n\\nMerrill Lynch Wealth Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015687</th>\n",
       "      <td>f69d7af8bcd1b2295781bc20bc662871</td>\n",
       "      <td>Strategic Customer Engagement Specialist, Korea</td>\n",
       "      <td>469</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>2018-05-22 15:04:00+00:00</td>\n",
       "      <td>2019-02-13 16:09:00+00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>US</td>\n",
       "      <td>NAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.amazon.com</td>\n",
       "      <td>ZXTILKJKG63JELOEG630</td>\n",
       "      <td>4295905494</td>\n",
       "      <td>2019-07-26 00:00:00</td>\n",
       "      <td>Do you have a knack for analyzing business dea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607423 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     hash  \\\n",
       "2        0234422f9c5eff7f6d1d008c3c31dae6   \n",
       "7        0c392d37eb6dfb15b1ffc2a48b8d95e7   \n",
       "8        0ee6d7263a67121e8405af8ad8fdef2a   \n",
       "9        0aaf97d36a5279ac18a43d1e34344232   \n",
       "13       05e060a4db459d502ed71fc78ea75f62   \n",
       "...                                   ...   \n",
       "1015682  fce9446a1c82c043b885ec53bd7c79e9   \n",
       "1015683  f69454c25df4c853541eecdfc4a3d0ef   \n",
       "1015684  f1399ba8d1ae6adddad701beb823a8f8   \n",
       "1015685  f6a9ba8e6c257788e5599388f770dfd0   \n",
       "1015687  f69d7af8bcd1b2295781bc20bc662871   \n",
       "\n",
       "                                                     title  company_id  \\\n",
       "2        UI Artist, Double Helix Games, Amazon Game Stu...         469   \n",
       "7        Warehouse Team Member (Seasonal, Part Time, Fl...         469   \n",
       "8        Responsable des opérations de contrôle d'inven...         469   \n",
       "9             Relationship Manager-Newton/Waltham, MA Area         381   \n",
       "13                     Database Administrator II - AMZ1781         469   \n",
       "...                                                    ...         ...   \n",
       "1015682                      Client Service Representative         381   \n",
       "1015683                                     DCO Lead(Away)         469   \n",
       "1015684  Director of Inclusion and Diversity - Minneton...         383   \n",
       "1015685                        Registered Client Associate         381   \n",
       "1015687    Strategic Customer Engagement Specialist, Korea         469   \n",
       "\n",
       "                        company_name                    created  \\\n",
       "2                   Amazon.com, Inc.  2015-06-20 02:39:07+00:00   \n",
       "7                   Amazon.com, Inc.  2019-01-15 16:06:00+00:00   \n",
       "8                   Amazon.com, Inc.  2018-04-17 15:04:00+00:00   \n",
       "9        Bank of America Corporation  2015-10-15 20:58:31+00:00   \n",
       "13                  Amazon.com, Inc.  2017-07-02 09:46:00+00:00   \n",
       "...                              ...                        ...   \n",
       "1015682  Bank of America Corporation  2017-10-10 00:03:00+00:00   \n",
       "1015683             Amazon.com, Inc.  2017-11-08 16:05:00+00:00   \n",
       "1015684      UnitedHealth Group Inc.  2017-07-25 22:08:00+00:00   \n",
       "1015685  Bank of America Corporation  2016-08-26 16:26:37+00:00   \n",
       "1015687             Amazon.com, Inc.  2018-05-22 15:04:00+00:00   \n",
       "\n",
       "                       delete_date ticker_symbol stock_exchange_country  \\\n",
       "2        2015-09-18 07:51:10+00:00          AMZN                     US   \n",
       "7                             None          AMZN                     US   \n",
       "8        2018-04-18 15:05:00+00:00          AMZN                     US   \n",
       "9        2015-10-23 06:54:04+00:00           BAC                     US   \n",
       "13       2017-07-22 19:00:00+00:00          AMZN                     US   \n",
       "...                            ...           ...                    ...   \n",
       "1015682  2017-10-17 04:16:56+00:00           BAC                     US   \n",
       "1015683  2017-11-15 16:18:17+00:00          AMZN                     US   \n",
       "1015684  2017-08-29 15:50:44+00:00           UNH                     US   \n",
       "1015685  2016-08-30 17:50:11+00:00           BAC                     US   \n",
       "1015687  2019-02-13 16:09:00+00:00          AMZN                     US   \n",
       "\n",
       "        stock_exchange_name  primary_flag                       company_url  \\\n",
       "2                       NAS           1.0             http://www.amazon.com   \n",
       "7                       NAS           1.0             http://www.amazon.com   \n",
       "8                       NAS           1.0             http://www.amazon.com   \n",
       "9                       NYS           1.0      http://www.bankofamerica.com   \n",
       "13                      NAS           1.0             http://www.amazon.com   \n",
       "...                     ...           ...                               ...   \n",
       "1015682                 NYS           1.0      http://www.bankofamerica.com   \n",
       "1015683                 NAS           1.0             http://www.amazon.com   \n",
       "1015684                 NYS           1.0  http://www.unitedhealthgroup.com   \n",
       "1015685                 NYS           1.0      http://www.bankofamerica.com   \n",
       "1015687                 NAS           1.0             http://www.amazon.com   \n",
       "\n",
       "                          lei open_perm_id   Next_Scrape_Change  \\\n",
       "2                        None         None  2017-01-30 00:00:00   \n",
       "7        ZXTILKJKG63JELOEG630   4295905494  2019-07-26 00:00:00   \n",
       "8        ZXTILKJKG63JELOEG630   4295905494  2019-07-26 00:00:00   \n",
       "9                        None         None  2015-10-23 00:00:00   \n",
       "13       ZXTILKJKG63JELOEG630   4295905494  2017-07-14 00:00:00   \n",
       "...                       ...          ...                  ...   \n",
       "1015682  9DJT3UXIJIZJI4WXO774   8589934339  2019-11-22 00:00:00   \n",
       "1015683  ZXTILKJKG63JELOEG630   4295905494  2019-07-26 00:00:00   \n",
       "1015684  549300GHBMY8T5GXDE41   5046300101  2017-09-06 00:00:00   \n",
       "1015685  9DJT3UXIJIZJI4WXO774   8589934339  2017-01-30 00:00:00   \n",
       "1015687  ZXTILKJKG63JELOEG630   4295905494  2019-07-26 00:00:00   \n",
       "\n",
       "                                               description  \n",
       "2        Amazon is all in on games.\\n\\nWe believe the e...  \n",
       "7        Shifts:\\n\\nOver-night, Early Morning, Day, Eve...  \n",
       "8        ous aimez l'action ?\\n\\nVous aimeriez travaill...  \n",
       "9        Located in a banking center, Relationship Mana...  \n",
       "13       MULTIPLE POSITIONS AVAILABLE Company: Amazon C...  \n",
       "...                                                    ...  \n",
       "1015682  Job Description:\\n\\nFinancial Center Client Se...  \n",
       "1015683  Are you passionate about finding process impro...  \n",
       "1015684  Here, you'll help attract, lead, support and r...  \n",
       "1015685  Business Overview\\n\\nMerrill Lynch Wealth Mana...  \n",
       "1015687  Do you have a knack for analyzing business dea...  \n",
       "\n",
       "[607423 rows x 15 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_records_joined[~job_records_joined.description.isnull()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
